{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5991f-8174-439d-9b90-d9acf1dc3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452ac6c-df84-4c28-a482-f31f5ccbab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update \n",
    "!sudo apt-get install -y libgl1\n",
    "!sudo apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c5fda-a184-45a7-8689-89ed1406db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d547e9f-1a0f-4572-8e4f-b6bc9fb612e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4149a56-c836-4667-bad6-00c996eb3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace experiment and model name ###\n",
    "\n",
    "experiment_name = \"DEFAULT REPLACE ME\"\n",
    "model_name = \"DEFAULT REPLACE ME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde31e1-344a-4099-84e1-9efedec0b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    model_path = \"forgery_detect_model.pt\"\n",
    "    input_schema = Schema([ColSpec(type=\"string\", name=\"image\")])\n",
    "    output_schema = Schema([ColSpec(type=\"string\", name=\"results_json\")])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    \n",
    "    # Step 1: Create the wrapper module file\n",
    "    module_path = \"yolo_wrapper.py\"\n",
    "    \n",
    "    with open(module_path, \"w\") as f:\n",
    "        f.write('''\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "class YOLOForgeryModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load the YOLO model from artifacts\"\"\"\n",
    "        from ultralytics import YOLO\n",
    "        \n",
    "        # Get model path from artifacts\n",
    "        model_path = context.artifacts[\"model\"]\n",
    "        \n",
    "        # Load the YOLO model\n",
    "        self.model = YOLO(model_path)\n",
    "    \n",
    "    def predict(self, *args, **kwargs):\n",
    "        \"\"\"Make predictions on input data\n",
    "        \n",
    "        MLflow may call this method in different ways:\n",
    "        - predict(model_input)\n",
    "        - predict(model_input, params=params)\n",
    "        - predict(context, model_input, params=params)\n",
    "        \"\"\"\n",
    "        # Parse arguments based on how MLflow calls the method\n",
    "        if len(args) == 1:\n",
    "            # Called as predict(model_input)\n",
    "            model_input = args[0]\n",
    "            params = kwargs.get('params', None)\n",
    "        elif len(args) == 2:\n",
    "            # Could be predict(context, model_input) or predict(model_input, params)\n",
    "            # Check if second arg looks like params\n",
    "            if isinstance(args[1], dict) and any(k in args[1] for k in ['temperature', 'max_tokens']):\n",
    "                model_input = args[0]\n",
    "                params = args[1]\n",
    "            else:\n",
    "                # Assume it's (context, model_input)\n",
    "                context = args[0]  # We don't use context in this implementation\n",
    "                model_input = args[1]\n",
    "                params = kwargs.get('params', None)\n",
    "        elif len(args) >= 3:\n",
    "            # Called as predict(context, model_input, params)\n",
    "            context = args[0]  # We don't use context in this implementation\n",
    "            model_input = args[1]\n",
    "            params = args[2] if len(args) > 2 else kwargs.get('params', None)\n",
    "        else:\n",
    "            # Fallback to kwargs\n",
    "            model_input = kwargs.get('model_input', kwargs.get('data', None))\n",
    "            params = kwargs.get('params', None)\n",
    "        \n",
    "        # Check if model is loaded\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not loaded. load_context must be called first.\")\n",
    "        \n",
    "        # Handle different input formats\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            # MLflow converts dict input to DataFrame with single row\n",
    "            if 'image' in model_input.columns:\n",
    "                image_path = model_input[\"image\"].iloc[0]\n",
    "            else:\n",
    "                # Fallback if column names are numeric\n",
    "                image_path = model_input.iloc[0, 0]\n",
    "        elif isinstance(model_input, dict):\n",
    "            # Direct dictionary input\n",
    "            image_path = model_input.get(\"image\")\n",
    "        else:\n",
    "            image_path = model_input\n",
    "        \n",
    "        # Load the image if it's a file path\n",
    "        if isinstance(image_path, str) and os.path.isfile(image_path):\n",
    "            # YOLO can handle file paths directly\n",
    "            image = image_path\n",
    "        elif isinstance(image_path, list):\n",
    "            # Convert list to numpy array\n",
    "            image = np.array(image_path, dtype=np.uint8)\n",
    "        elif isinstance(image_path, np.ndarray):\n",
    "            # Use numpy array directly\n",
    "            image = image_path\n",
    "        else:\n",
    "            # For any other format, try to use as-is\n",
    "            image = image_path\n",
    "        \n",
    "        # Run YOLO prediction\n",
    "        results = self.model.predict(image)\n",
    "        \n",
    "        # Process results\n",
    "        output_list = []\n",
    "        for result in results:\n",
    "            # Get summary from YOLO result\n",
    "            summary = result.summary()\n",
    "            \n",
    "            if summary and len(summary) > 0:\n",
    "                # Extract prediction details\n",
    "                result_dict = {\n",
    "                    \"prediction\": summary[0].get('name', 'unknown'),\n",
    "                    \"confidence\": float(summary[0].get('confidence', 0.0))\n",
    "                }\n",
    "            else:\n",
    "                # No detections\n",
    "                result_dict = {\n",
    "                    \"prediction\": \"no_detection\",\n",
    "                    \"confidence\": 0.0\n",
    "                }\n",
    "            \n",
    "            output_list.append(result_dict)\n",
    "        \n",
    "        # Return first result as JSON string\n",
    "        final_result = output_list[0] if output_list else {\"prediction\": \"error\", \"confidence\": 0.0}\n",
    "        \n",
    "        # Return in the format expected by the output schema\n",
    "        return pd.DataFrame([{\"results_json\": json.dumps(final_result)}])\n",
    "\n",
    "def _load_pyfunc(data_path):\n",
    "    \"\"\"Load function that MLflow will call\n",
    "    \n",
    "    Note: data_path is the path to the YOLO model file\n",
    "    \"\"\"\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Create model instance\n",
    "    model_instance = YOLOForgeryModel()\n",
    "    \n",
    "    # Since we're using loader_module pattern, we need to load the model here\n",
    "    # The data_path is the actual YOLO model file path\n",
    "    model_instance.model = YOLO(data_path)\n",
    "    \n",
    "    return model_instance\n",
    "    ''')\n",
    "    \n",
    "    # Step 2: Define model schemas using the correct approach\n",
    "    input_schema = Schema([ColSpec(type=\"string\", name=\"image\")])\n",
    "    output_schema = Schema([ColSpec(type=\"string\", name=\"results_json\")])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "    \n",
    "   \n",
    "    if mlflow.active_run() is None:\n",
    "        mlflow.start_run()\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        loader_module=\"yolo_wrapper\",\n",
    "        data_path=model_path,\n",
    "        code_paths=[module_path],\n",
    "        signature=signature,\n",
    "        pip_requirements=[\n",
    "            \"mlflow>=2.0.0\",\n",
    "            \"ultralytics>=8.0.0\",\n",
    "            \"torch>=1.7.0\",\n",
    "            \"numpy>=1.18.0\",\n",
    "            \"pillow>=7.0.0\",\n",
    "            \"pandas>=1.0.0\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Step 5: Get the current run ID\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    \n",
    "    # Step 6: Register the model with the MLflow Model Registry\n",
    "    model_name = model_name\n",
    "    model_version = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/model\",\n",
    "        name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Model registered as {model_name} version {model_version.version}\")\n",
    "    \n",
    "    # End the run\n",
    "    mlflow.end_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a9f137-837c-4229-abc4-ccaa447a7033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={}, params={}, tags={'mlflow.log-model.history': '[{\"run_id\": \"74320470f12a473490f9230d6e3a08d7\", '\n",
       "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
       "                             '\"2025-05-22 18:00:45.473336\", \"model_uuid\": '\n",
       "                             '\"66115c8403f146fea946faa224b4446c\", \"flavors\": '\n",
       "                             '{\"python_function\": {\"streamable\": false, '\n",
       "                             '\"loader_module\": \"yolo_wrapper\", '\n",
       "                             '\"python_version\": \"3.12.7\", \"data\": '\n",
       "                             '\"data/forgery_detect_model.pt\", \"env\": {\"conda\": '\n",
       "                             '\"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}, '\n",
       "                             '\"code\": \"code\"}}}]',\n",
       " 'mlflow.runName': 'marvelous-shad-913',\n",
       " 'mlflow.source.name': '/opt/conda/lib/python3.12/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'jovyan'}>, info=<RunInfo: artifact_uri='/phoenix/mlflow/511465038541425052/74320470f12a473490f9230d6e3a08d7/artifacts', end_time=1747936846627, experiment_id='511465038541425052', lifecycle_stage='active', run_id='74320470f12a473490f9230d6e3a08d7', run_name='marvelous-shad-913', run_uuid='74320470f12a473490f9230d6e3a08d7', start_time=1747936845239, status='FINISHED', user_id='jovyan'>, inputs=<RunInputs: dataset_inputs=[]>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.last_active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172ce2f-6e7d-4f13-99c7-9c6d5926d535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
