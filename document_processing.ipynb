{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f242f73-e0b1-492d-8447-f1789acc8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf2image opencv-python ipywidgets ultralytics scikit-image pymupdf pygments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c65a20-a1f8-451f-9fa4-5e47583d679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update \n",
    "!sudo apt-get install -y libgl1\n",
    "!sudo apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df5993-b8d2-4553-8fe5-096c6f1f5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import fitz\n",
    "import difflib\n",
    "from ultralytics import YOLO\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "from IPython.display import display, HTML\n",
    "import pygments\n",
    "from pygments.lexers import DiffLexer\n",
    "from pygments.formatters import HtmlFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eebab3-b926-453b-83ec-815ba2503c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079033b-9706-446f-b311-9d978fb35cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE VISION MODEL TO LOCATE AND EXTRACT SIGNATURES FROM A PDF DOCUMENT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f7aee-2ac0-4101-82f8-a5400d983731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload a PDF file with a signature\n",
    "\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.pdf',  \n",
    "    multiple=False \n",
    ")\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5e344-18ae-48e1-b2d5-e0526d59bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert PDF to image for processing\n",
    "\n",
    "model = YOLO(\"../shared/model_training_scripts/YOLOv11_Signature_Detection/YOLOv11_train_20250520_114332/weights/best.pt\")\n",
    "\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "pdf_images = convert_from_bytes(uploader.value[0].content.tobytes(), fmt=\"jpeg\")\n",
    "print(f\"PDF contains {len(pdf_images)} pages\")\n",
    "\n",
    "# Process each page\n",
    "signatures_by_page = {}\n",
    "\n",
    "for page_num, img in enumerate(pdf_images, 1):\n",
    "    # Save the page image\n",
    "    page_filename = f\"temp/pdfimg_page{page_num}.jpeg\"\n",
    "    img.save(page_filename)\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "    # Detect signatures in the PDF\n",
    "    pred = model(page_filename)\n",
    "    signatures_this_page = []\n",
    "    for i, p in enumerate(pred):\n",
    "        boxes = p.boxes\n",
    "        \n",
    "        # Check if we have any detections\n",
    "        if len(boxes) == 0:\n",
    "            print(f\"  No signatures detected on page {page_num}\")\n",
    "            continue\n",
    "            \n",
    "        # Get confidence scores and convert to numpy if needed\n",
    "        conf_scores = boxes.conf\n",
    "        if hasattr(conf_scores, 'cpu'):\n",
    "            conf_scores = conf_scores.cpu().numpy()\n",
    "            \n",
    "        # Get bounding boxes and convert to numpy if needed\n",
    "        bboxes = boxes.xyxy\n",
    "        if hasattr(bboxes, 'cpu'):\n",
    "            bboxes = bboxes.cpu().numpy()\n",
    "            \n",
    "        print(f\"  Found {len(conf_scores)} potential signatures on page {page_num}\")\n",
    "        \n",
    "        # Process detections and filter by confidence\n",
    "        for j, conf in enumerate(conf_scores):\n",
    "            if conf > 0.5:  # Apply confidence threshold\n",
    "                # Format confidence for filename\n",
    "                conf_formatted = f\"{conf:.2f}\"\n",
    "                \n",
    "                # Create filename with page, detection index and confidence\n",
    "                crop_filename = f\"signature_page{page_num}_det{j+1}_conf{conf_formatted}\"\n",
    "                \n",
    "                # Get bounding box\n",
    "                x1, y1, x2, y2 = bboxes[j]\n",
    "                \n",
    "                # Manual crop using PIL\n",
    "                original_img = Image.open(page_filename)\n",
    "                crop_img = original_img.crop((int(x1), int(y1), int(x2), int(y2)))\n",
    "                \n",
    "                # Save cropped image\n",
    "                crop_path = os.path.join('temp', f\"{crop_filename}.jpg\")\n",
    "                crop_img.save(crop_path)\n",
    "                \n",
    "                # Add to page signatures\n",
    "                signatures_this_page.append((crop_path, conf))\n",
    "                \n",
    "                print(f\"  Saved signature {j+1} with confidence: {conf:.2f}\")\n",
    "        \n",
    "        # Visualize all detections with confidence scores\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        img = plt.imread(page_filename)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        for j, (conf, box) in enumerate(zip(conf_scores, bboxes)):\n",
    "            x1, y1, x2, y2 = box\n",
    "            \n",
    "            # Choose color based on confidence\n",
    "            if conf > 0.5:  # Above threshold\n",
    "                color = 'green'\n",
    "                linewidth = 2\n",
    "                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                linewidth=linewidth, edgecolor=color, facecolor='none')\n",
    "                plt.gca().add_patch(rect)\n",
    "                \n",
    "                # Add text with confidence\n",
    "                plt.text(x1, y1-5, f\"{j+1}: {conf:.2f}\", \n",
    "                        color='white', fontsize=12, \n",
    "                        bbox=dict(facecolor=color, alpha=0.7))\n",
    "            else:  # Below threshold\n",
    "                color = None\n",
    "                linewidth = None\n",
    "             \n",
    "                  \n",
    "            \n",
    "        plt.title(f\"Page {page_num} - Signatures (green: conf > 50%)\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Store results for this page\n",
    "    signatures_by_page[page_num] = signatures_this_page\n",
    "    \n",
    "    high_conf_count = len(signatures_this_page)\n",
    "\n",
    "\n",
    "# Calculate total signatures\n",
    "total_signatures = sum(len(sigs) for sigs in signatures_by_page.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0e83b-17d4-4410-a788-2d40591160bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crop signatures for display\n",
    "\n",
    "def display_only_crops(signatures_by_page):\n",
    "    \"\"\"\n",
    "    Display only the cropped signature images - nothing else\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    import os\n",
    "    \n",
    "    # Extract all signature paths\n",
    "    all_signature_paths = []\n",
    "    for page_signatures in signatures_by_page.values():\n",
    "        for sig_path, _ in page_signatures:\n",
    "            if os.path.exists(sig_path):\n",
    "                all_signature_paths.append(sig_path)\n",
    "    \n",
    "    # Check if any signatures were found\n",
    "    if not all_signature_paths:\n",
    "        print(\"No signature crops found\")\n",
    "        return\n",
    "    \n",
    "    # Build minimal HTML with just the images\n",
    "    html_content = '<div style=\"display: flex; flex-wrap: wrap; gap: 10px;\">'\n",
    "    \n",
    "    for sig_path in all_signature_paths:\n",
    "        html_content += f'<img src=\"{sig_path}\" style=\"max-width: 200px; max-height: 100px; margin: 5px;\">'\n",
    "    \n",
    "    html_content += '</div>'\n",
    "    \n",
    "    # Display just the images\n",
    "    display(HTML(html_content))\n",
    "\n",
    "# Display only the cropped signature images\n",
    "display_only_crops(signatures_by_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fd0d8-4bed-4078-bf8f-e17c48a3a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANALYZE PDF FILES FOR EDITING OR MANIPULATIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c69ce4-f9be-496e-8592-3c1b07c1720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload PDF for Analysis\n",
    "\n",
    "pdf_uploader = widgets.FileUpload(\n",
    "    accept='.pdf',  \n",
    "    multiple=False \n",
    ")\n",
    "display(pdf_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154ea36-f1d0-4e35-b233-5b8bc050c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and save all versions of PDF\n",
    "\n",
    "pdf_content = pdf_uploader.value[0].content.tobytes()\n",
    "\n",
    "startxref_positions = [m.start() for m in re.finditer(b'startxref', pdf_content)]\n",
    "        \n",
    "if len(startxref_positions) <= 1:\n",
    "    print(\"No incremental updates detected in this PDF.\")\n",
    "\n",
    "print(f\"Found {len(startxref_positions)} potential versions\")\n",
    "\n",
    "# # Find all EOF positions\n",
    "eof_positions = [pdf_content.find(b'%%EOF', pos) + 5 for pos in startxref_positions]\n",
    "\n",
    "# # Extract and save all versions\n",
    "version_paths = []\n",
    "\n",
    "for i in range(len(eof_positions)):\n",
    "    version_num = i + 1\n",
    "    output_path = (f\"temp/version_{version_num}.pdf\")\n",
    "    \n",
    "    # Each version includes everything up to its EOF marker\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(pdf_content[:eof_positions[i]])\n",
    "    \n",
    "    version_paths.append(output_path)\n",
    "    print(f\"Version {version_num} saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b620ea-7dea-4b45-950a-e1745ad45c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(version_paths) <= 1:\n",
    "    print(\"Need at least two versions to compare\")\n",
    "    # Exit or handle this case appropriately\n",
    "else:\n",
    "    # Extract text from each version (outside of any comparison loop)\n",
    "    version_texts = []\n",
    "    for path in version_paths:\n",
    "        try:\n",
    "            doc = fitz.open(path)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(doc)):\n",
    "                text += doc[page_num].get_text()\n",
    "            version_texts.append(text)\n",
    "            doc.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {path}: {e}\")\n",
    "            version_texts.append(\"\")\n",
    "    \n",
    "    # AFTER extracting all texts, then do comparisons\n",
    "    # Compare consecutive versions\n",
    "    for i in range(len(version_texts) - 1):\n",
    "        prev_text = version_texts[i]\n",
    "        curr_text = version_texts[i+1]\n",
    "        \n",
    "        print(f\"\\nComparing Version {i+1} with Version {i+2}:\")\n",
    "        \n",
    "        # Check if either text is None or empty\n",
    "        if prev_text is None or curr_text is None or prev_text.strip() == \"\" or curr_text.strip() == \"\":\n",
    "            print(f\"  Skipping comparison - text extraction failed or empty for Version {i+1} or Version {i+2}\")\n",
    "            continue\n",
    "        \n",
    "        # Basic difference check\n",
    "        if prev_text == curr_text:\n",
    "            print(\"  No text differences detected\")\n",
    "        else:\n",
    "            # Create a unified diff\n",
    "            diff = list(difflib.unified_diff(\n",
    "                prev_text.splitlines(),\n",
    "                curr_text.splitlines(),\n",
    "                fromfile=f'Version {i+1}',\n",
    "                tofile=f'Version {i+2}',\n",
    "                lineterm=''\n",
    "            ))\n",
    "            \n",
    "            # Count additions and removals\n",
    "            additions = len([line for line in diff if line.startswith('+')])\n",
    "            removals = len([line for line in diff if line.startswith('-')])\n",
    "            print(f\"  Changes: {additions} additions, {removals} removals\")\n",
    "            \n",
    "            # Save detailed diff to file\n",
    "            output_dir = os.path.dirname(version_paths[0])\n",
    "            diff_path = os.path.join(output_dir, f\"diff_v{i+1}_v{i+2}.txt\")\n",
    "            \n",
    "            with open(diff_path, 'w', encoding='utf-8') as f:\n",
    "                f.write('\\n'.join(diff))\n",
    "            print(f\"  Detailed differences saved to {diff_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3053f49-b3fe-49d1-acf3-04e76af43b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the diff\n",
    "with open(diff_path, 'r', encoding='utf-8') as f:\n",
    "    diff_content = f.read()\n",
    "html_lines = []\n",
    "for line in diff_content.split('\\n'):\n",
    "    if line.startswith('+'):\n",
    "        html_lines.append(f'<span style=\"background-color: #e6ffec; color: #22863a\">{line}</span>')\n",
    "    elif line.startswith('-'):\n",
    "        html_lines.append(f'<span style=\"background-color: #ffebe9; color: #cb2431\">{line}</span>')\n",
    "    elif line.startswith('@@'):\n",
    "        html_lines.append(f'<span style=\"color: #6f42c1\">{line}</span>')\n",
    "    elif line.startswith('---') or line.startswith('+++'):\n",
    "        html_lines.append(f'<span style=\"font-weight: bold\">{line}</span>')\n",
    "    else:\n",
    "        html_lines.append(line)\n",
    "\n",
    "formatted_diff = '<pre style=\"font-family: monospace;\">' + '<br>'.join(html_lines) + '</pre>'\n",
    "display(HTML(formatted_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e27332-4592-4059-89ab-18b838c60634",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check a PDF for physical changes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb01a77-10c3-484d-839f-9b55ada87192",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2_uploader = widgets.FileUpload(\n",
    "    accept='.pdf',  \n",
    "    multiple=False \n",
    ")\n",
    "display(pdf2_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18a369-3051-4064-83ee-bd07c695e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas of deviation are highlighted and/or outlined\n",
    "\n",
    "pdf_images = convert_from_bytes(uploader.value[0].content.tobytes(), fmt=\"jpeg\")\n",
    "\n",
    "class ModdedDocAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.lower_bound = np.array([0, 10, 10])\n",
    "        self.upper_bound = np.array([179, 255, 245])\n",
    "    \n",
    "    def convert_to_ela_image(self, image, quality=90):\n",
    "        \"\"\"Performs Error Level Analysis on an image.\"\"\"\n",
    "        # Save the image to a temporary file\n",
    "        temp_output = io.BytesIO()\n",
    "        image.save(temp_output, format=\"JPEG\", quality=quality)\n",
    "        temp_output.seek(0)\n",
    "        \n",
    "        # Open the temporary saved image\n",
    "        temp_image = Image.open(temp_output)\n",
    "        \n",
    "        # Calculate the difference between the original and the saved image\n",
    "        ela_image = ImageChops.difference(image, temp_image)\n",
    "        \n",
    "        # Scale the differences to make them visible\n",
    "        extrema = ela_image.getextrema()\n",
    "        max_diff = max([ex[1] for ex in extrema])\n",
    "        if max_diff == 0:\n",
    "            max_diff = 1\n",
    "        scale = 255.0 / max_diff\n",
    "        \n",
    "        # Enhance the differences\n",
    "        ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "        \n",
    "        return ela_image\n",
    "    \n",
    "    def highlight_deviations(self, ela_image, threshold=20):\n",
    "        \"\"\"Highlights deviations in an ELA image based on a threshold.\"\"\"\n",
    "        ela_array = np.array(ela_image)\n",
    "        mask = (ela_array > threshold).astype(np.uint8) * 255\n",
    "        return Image.fromarray(mask)\n",
    "    \n",
    "    def detect_highlighted_areas(self, image):\n",
    "        \"\"\"Detect and mark suspicious areas in the image.\"\"\"\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        mask = cv2.inRange(hsv, self.lower_bound, self.upper_bound)\n",
    "        \n",
    "        # Morphological operations for noise reduction\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.erode(mask, kernel, iterations=1)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        suspicious_areas = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 50:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                suspicious_areas.append((x, y, w, h))\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        return suspicious_areas, image\n",
    "    \n",
    "    def analyze_pdf(self, pdf_img):\n",
    "        \"\"\"Perform complete deepfake analysis on a PDF.\"\"\"\n",
    "        try:\n",
    "            # Perform ELA analysis\n",
    "            ela_image = self.convert_to_ela_image(pdf_img, quality=90)\n",
    "            \n",
    "            # Detect suspicious areas\n",
    "            deviation = self.highlight_deviations(ela_image, threshold=20)\n",
    "            \n",
    "            # Convert PIL images to numpy for OpenCV processing\n",
    "            ela_array = np.array(ela_image)\n",
    "            \n",
    "            # Convert RGB to BGR for OpenCV\n",
    "            if len(ela_array.shape) == 3 and ela_array.shape[2] == 3:\n",
    "                ela_array = cv2.cvtColor(ela_array, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "            # Find and mark suspicious areas\n",
    "            suspicious_areas, marked_image = self.detect_highlighted_areas(ela_array)\n",
    "            \n",
    "            # Convert images to base64 for web display\n",
    "            def pil_to_base64(pil_img):\n",
    "                buffered = io.BytesIO()\n",
    "                pil_img.save(buffered, format=\"PNG\")\n",
    "                return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "            \n",
    "            # Convert OpenCV image to base64\n",
    "            def cv_to_base64(cv_img):\n",
    "                _, buffer = cv2.imencode('.png', cv_img)\n",
    "                return base64.b64encode(buffer).decode('utf-8')\n",
    "            \n",
    "            results = {\n",
    "                \"suspicious_areas_count\": len(suspicious_areas),\n",
    "                \"suspicious_areas\": suspicious_areas,\n",
    "                \"images\": {\n",
    "                    \"ela_analysis\": pil_to_base64(ela_image),\n",
    "                    \"deviation_mask\": pil_to_base64(deviation),\n",
    "                    \"marked_areas\": cv_to_base64(marked_image)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing PDF: {e}\")\n",
    "            return None\n",
    "\n",
    "analyzer = ModdedDocAnalyzer()\n",
    "\n",
    "for img in pdf_images:\n",
    "    results = analyzer.analyze_pdf(img)\n",
    "    if results.get('suspicious_areas_count') == 0:\n",
    "        print(\"No suspicious areas found...\")\n",
    "    else:\n",
    "        print(f\"{results.get('suspicious_areas_count')} suspcious areas found. View below.\")\n",
    "        deviation_img = results.get('images').get('deviation_mask')\n",
    "        image_d = base64.b64decode(deviation_img)\n",
    "        dev_img = Image.open(io.BytesIO(image_d))\n",
    "        \n",
    "        dev_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b969813-9e56-4564-a293-5f0ce378685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Forgery Detection ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e517d-573a-4c5b-88eb-51d2d75cda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First upload known genuine signature image\n",
    "\n",
    "sig_uploader = widgets.FileUpload(\n",
    "    accept='image/*',  \n",
    "    multiple=False \n",
    ")\n",
    "display(sig_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac5a86-d9be-4dc1-b4c8-3af876a7ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process and save uploaded image\n",
    "\n",
    "genuine_sig = sig_uploader.value[0].content.tobytes()\n",
    "image = Image.open(io.BytesIO(genuine_sig))\n",
    "image.save(\"temp/genuine_sig.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53b362-c984-4379-b5bb-1d1a6d670ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 - Upload questionable signature\n",
    "\n",
    "compare_uploader = widgets.FileUpload(\n",
    "    accept='image/*',  \n",
    "    multiple=False \n",
    ")\n",
    "display(compare_uploader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bb109-df4a-4097-b53b-6d7a8c471c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process and save uploaded image\n",
    "\n",
    "questioned_sig = compare_uploader.value[0].content.tobytes()\n",
    "image = Image.open(io.BytesIO(questioned_sig))\n",
    "image.save(\"temp/questioned_sig.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91855d-2673-422d-901e-ad52b8cb62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Compare for forgery with custom trained vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39638c8-3596-4fd8-901a-5dad0ce45799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load mlflow model and install requirements for model specific environment\n",
    "\n",
    "%pip install -r /phoenix/mlflow/663313515098042442/850a1e3ce11b4259b700fc66c1275819/artifacts/ensemble_signature_verifier/requirements.txt\n",
    "logged_model = 'runs:/850a1e3ce11b4259b700fc66c1275819/ensemble_signature_verifier'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b340a-5b3b-41ea-9377-058d8e2a2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load comparison images\n",
    "\n",
    "genuine_signature ='temp/genuine_sig.jpeg'\n",
    "questioned_signature = 'temp/questioned_sig.jpeg'\n",
    "\n",
    "# Extract features from each signature\n",
    "\n",
    "img1 = cv2.imread(genuine_signature, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(questioned_signature, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Enhanced preprocessing\n",
    "img1 = cv2.bilateralFilter(img1, 9, 75, 75)\n",
    "img2 = cv2.bilateralFilter(img2, 9, 75, 75)\n",
    "\n",
    "# Multiple scale analysis\n",
    "scales = [(128, 64), (256, 128), (64, 32)]\n",
    "features = []\n",
    "\n",
    "for scale in scales:\n",
    "    img1_scaled = cv2.resize(img1, scale)\n",
    "    img2_scaled = cv2.resize(img2, scale)\n",
    "    \n",
    "    # SSIM at different scales\n",
    "    ssim_val = ssim(img1_scaled, img2_scaled)\n",
    "    features.append(ssim_val)\n",
    "    \n",
    "    # Histogram comparison at multiple scales\n",
    "    for bins in [32, 64]:\n",
    "        hist1 = cv2.calcHist([img1_scaled], [0], None, [bins], [0, 256])\n",
    "        hist2 = cv2.calcHist([img2_scaled], [0], None, [bins], [0, 256])\n",
    "        cv2.normalize(hist1, hist1, 0, 1, cv2.NORM_MINMAX)\n",
    "        cv2.normalize(hist2, hist2, 0, 1, cv2.NORM_MINMAX)\n",
    "        \n",
    "        features.append(cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL))\n",
    "        features.append(cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA))\n",
    "\n",
    "# Writer-specific features\n",
    "# 1. Slant analysis\n",
    "def calculate_slant(img):\n",
    "    try:\n",
    "        edges = cv2.Canny(img, 50, 150)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=50)\n",
    "        angles = []\n",
    "        if lines is not None:\n",
    "            for line in lines[:10]:\n",
    "                angle = line[0][1]\n",
    "                if not np.isnan(angle):\n",
    "                    angles.append(angle)\n",
    "        return np.mean(angles) if angles else 0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "slant1 = calculate_slant(img1)\n",
    "slant2 = calculate_slant(img2)\n",
    "features.extend([slant1, slant2, abs(slant1 - slant2)])\n",
    "\n",
    "# 2. Aspect ratio analysis\n",
    "def get_bounding_box_features(img):\n",
    "    try:\n",
    "        contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours and len(contours) > 0:\n",
    "            x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "            if h > 0:\n",
    "                return w/h, w, h\n",
    "        return 1.0, 0, 0\n",
    "    except:\n",
    "        return 1.0, 0, 0\n",
    "\n",
    "aspect1, w1, h1 = get_bounding_box_features(img1)\n",
    "aspect2, w2, h2 = get_bounding_box_features(img2)\n",
    "features.extend([aspect1, aspect2, abs(aspect1 - aspect2), abs(w1-w2), abs(h1-h2)])\n",
    "\n",
    "# 3. Fixed pressure variation estimation\n",
    "def estimate_pressure_variation(img):\n",
    "    try:\n",
    "        _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        if not binary.any():\n",
    "            return 0.0\n",
    "        distances = cv2.distanceTransform(binary, cv2.DIST_L2, 5)\n",
    "        valid_distances = distances[distances > 0]\n",
    "        if len(valid_distances) <= 1:\n",
    "            return 0.0\n",
    "        std_val = np.std(valid_distances)\n",
    "        return float(std_val) if not np.isnan(std_val) else 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "pressure_var1 = estimate_pressure_variation(img1)\n",
    "pressure_var2 = estimate_pressure_variation(img2)\n",
    "features.extend([pressure_var1, pressure_var2, abs(pressure_var1 - pressure_var2)])\n",
    "\n",
    "# Original proven features\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "if des1 is not None and des2 is not None and len(kp1) > 0 and len(kp2) > 0:\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    num_matches = len(matches)\n",
    "    avg_distance = sum(m.distance for m in matches) / num_matches if num_matches > 0 else 100\n",
    "    match_ratio = num_matches / min(len(kp1), len(kp2)) if min(len(kp1), len(kp2)) > 0 else 0\n",
    "    \n",
    "    features.extend([num_matches, avg_distance, len(kp1), len(kp2), match_ratio])\n",
    "else:\n",
    "    features.extend([0, 100, 0, 0, 0])\n",
    "\n",
    "# Ensure all features are valid numbers\n",
    "features = np.array(features, dtype=np.float64)\n",
    "features = np.nan_to_num(features, nan=0.0, posinf=100.0, neginf=-100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab862b1-afc4-464f-aacd-bc305585261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Prediction\n",
    "features_array = np.array(features, dtype=np.float64).reshape(1, -1)\n",
    "prediction = loaded_model.predict(features_array)\n",
    "probabilities = prediction[0]\n",
    "forgery_prob, genuine_prob = probabilities\n",
    "is_genuine = genuine_prob > forgery_prob\n",
    "confidence = max(genuine_prob, forgery_prob)\n",
    "\n",
    "if confidence > 0.90:\n",
    "    ccolor = '#28a745'  # Green\n",
    "    confidence_text = \"High\"\n",
    "elif confidence >= 0.75:\n",
    "    ccolor = '#ffc107'  # Yellow\n",
    "    confidence_text = \"Medium\"\n",
    "else:\n",
    "    ccolor = '#dc3545'  # Red\n",
    "    confidence_text = \"Low\"\n",
    "    \n",
    "conf_format = format(confidence*100, '.2f')\n",
    "if is_genuine:\n",
    "    conf_text = \"Genuine\"\n",
    "    icon = \"✓\"\n",
    "else:\n",
    "    conf_text = \"Forgery\"\n",
    "    icon = \"✗\"\n",
    "    \n",
    "conf_html = f\"\"\"\n",
    "<div style=\"font-family: 'Segoe UI', Arial, sans-serif; max-width: 500px; margin: 20px auto; \n",
    "            padding: 20px; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); \n",
    "            background: #f8f9fa;\">\n",
    "    <h2 style=\"text-align: center; color: #343a40; margin-top: 0;\">Signature Verification</h2>\n",
    "    <hr style=\"border: 0; height: 1px; background-image: linear-gradient(to right, rgba(0,0,0,0), rgba(0,0,0,0.2), rgba(0,0,0,0));\">\n",
    "    \n",
    "    <div style=\"display: flex; align-items: center; justify-content: center; margin: 25px 0;\">\n",
    "        <div style=\"width: 80px; height: 80px; border-radius: 50%; background-color: {ccolor}; \n",
    "                  display: flex; align-items: center; justify-content: center; color: white; \n",
    "                  font-size: 38px; font-weight: bold;\">{icon}</div>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"text-align: center; margin: 20px 0;\">\n",
    "        <h3 style=\"font-size: 24px; margin-bottom: 5px; color: {ccolor};\">{conf_text}</h3>\n",
    "        <p style=\"font-size: 18px; margin-top: 5px; color: #6c757d;\">\n",
    "            with <span style=\"color: {ccolor}; font-weight: bold;\">{conf_format}%</span> confidence\n",
    "        </p>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background-color: rgba(0,0,0,0.05); border-radius: 5px; padding: 10px; margin-top: 15px;\">\n",
    "        <p style=\"margin: 0; color: #6c757d; font-size: 14px;\">\n",
    "            <strong>Confidence Level:</strong> {confidence_text}\n",
    "        </p>\n",
    "        <div style=\"height: 6px; background-color: #e9ecef; border-radius: 3px; margin-top: 8px;\">\n",
    "            <div style=\"width: {conf_format}%; height: 100%; background-color: {ccolor}; border-radius: 3px;\"></div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"margin-top: 20px; font-size: 12px; color: #adb5bd; text-align: center;\">\n",
    "        Generated on {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import HTML\n",
    "from datetime import datetime\n",
    "HTML(conf_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c56f5772-67d6-4c41-96b6-c6fa355b135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Temp folder for next run\n",
    "\n",
    "import os, shutil\n",
    "folder = 'temp'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
