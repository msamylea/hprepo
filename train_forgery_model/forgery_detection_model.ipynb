{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f19b2-4902-4eb8-84d7-a1191bf44dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c4b4f-616d-4088-958b-2751c509d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "    --extra-index-url=https://pypi.nvidia.com \\\n",
    "    \"cudf-cu12==25.4.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b13c3e-bc04-4c7a-8b22-cd959404a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update \n",
    "!sudo apt-get install -y libgl1\n",
    "!sudo apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cef89-0c53-42a0-9948-f76bc407b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab2fc6-5b02-42af-9136-42096695743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "\n",
    "mlflow.set_experiment(\"forgery_detection_experiment\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d9639-fb54-4eb8-9d4a-522731954c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '../../datafabric/forgery_detect_dataset/full'\n",
    "csv_file = '../../datafabric/forgery_detect_dataset/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f48300-5d0f-4954-b8a0-1d9b9ea849da",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90671bd-d0e7-4d00-8959-46a78364b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedSignatureNet(nn.Module):\n",
    "    \"\"\"Optimized neural network based on Optuna findings.\"\"\"\n",
    "    def __init__(self, trial=None, input_size=None, num_layers=None, first_layer_size=None, \n",
    "                 layer_reductions=None, dropout_rate=None):\n",
    "        super(OptimizedSignatureNet, self).__init__()\n",
    "        \n",
    "        if trial is not None:\n",
    "            # Original Optuna-based initialization\n",
    "            num_layers = trial.suggest_int(\"num_layers\", 4, 5)\n",
    "            first_layer_size = trial.suggest_int(\"first_layer_size\", 512, 768, step=128)\n",
    "            \n",
    "            layer_sizes = [first_layer_size]\n",
    "            current_size = first_layer_size\n",
    "            \n",
    "            for i in range(1, num_layers):\n",
    "                reduction = trial.suggest_float(f\"layer_{i}_reduction\", 0.7, 0.85)\n",
    "                current_size = int(current_size * reduction)\n",
    "                layer_sizes.append(max(current_size, 64))\n",
    "            \n",
    "            self.dropout_rate = trial.suggest_float(\"dropout_rate\", 0.3, 0.5)\n",
    "            \n",
    "            # Build the network layers\n",
    "            self.layers = nn.ModuleList()\n",
    "            for i in range(len(layer_sizes)):\n",
    "                if i == 0:\n",
    "                    # First layer\n",
    "                    self.layers.append(nn.Linear(input_size, layer_sizes[i]))\n",
    "                else:\n",
    "                    # Subsequent layers\n",
    "                    self.layers.append(nn.Linear(layer_sizes[i-1], layer_sizes[i]))\n",
    "            \n",
    "            # Output layer\n",
    "            self.output = nn.Linear(layer_sizes[-1], 2)  # Binary classification\n",
    "            \n",
    "        else:\n",
    "            # Direct parameter initialization for loading saved models\n",
    "            layer_sizes = [first_layer_size]\n",
    "            current_size = first_layer_size\n",
    "            \n",
    "            for reduction in layer_reductions:\n",
    "                current_size = int(current_size * reduction)\n",
    "                layer_sizes.append(max(current_size, 64))\n",
    "            \n",
    "            self.dropout_rate = dropout_rate\n",
    "            \n",
    "            # Build the network layers\n",
    "            self.layers = nn.ModuleList()\n",
    "            for i in range(len(layer_sizes)):\n",
    "                if i == 0:\n",
    "                    # First layer\n",
    "                    self.layers.append(nn.Linear(input_size, layer_sizes[i]))\n",
    "                else:\n",
    "                    # Subsequent layers\n",
    "                    self.layers.append(nn.Linear(layer_sizes[i-1], layer_sizes[i]))\n",
    "            \n",
    "            # Output layer\n",
    "            self.output = nn.Linear(layer_sizes[-1], 2)  # Binary classification\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.batch_norms = nn.ModuleList([nn.BatchNorm1d(size) for size in layer_sizes])\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        \n",
    "        # Initialize weights\n",
    "        for layer in self.layers:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0)\n",
    "        nn.init.xavier_uniform_(self.output.weight)\n",
    "        nn.init.constant_(self.output.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, (layer, batch_norm) in enumerate(zip(self.layers, self.batch_norms)):\n",
    "            x = layer(x)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df820f60-ce5d-4480-b5eb-718515ca27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureCache:\n",
    "    def __init__(self, cache_dir=\"feature_cache\"):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.cache_index_file = self.cache_dir / \"cache_index.json\"\n",
    "        self.load_cache_index()\n",
    "    \n",
    "    def load_cache_index(self):\n",
    "        \"\"\"Load the cache index\"\"\"\n",
    "        if self.cache_index_file.exists():\n",
    "            with open(self.cache_index_file, 'r') as f:\n",
    "                self.cache_index = json.load(f)\n",
    "        else:\n",
    "            self.cache_index = {}\n",
    "    \n",
    "    def save_cache_index(self):\n",
    "        \"\"\"Save the cache index\"\"\"\n",
    "        with open(self.cache_index_file, 'w') as f:\n",
    "            json.dump(self.cache_index, f)\n",
    "    \n",
    "    def get_file_hash(self, filepath):\n",
    "        \"\"\"Get a hash of the file for cache key\"\"\"\n",
    "        stat = os.stat(filepath)\n",
    "        file_info = f\"{filepath}_{stat.st_size}_{stat.st_mtime}\"\n",
    "        return hashlib.md5(file_info.encode()).hexdigest()\n",
    "    \n",
    "    def get_cache_key(self, img1_path, img2_path):\n",
    "        \"\"\"Generate cache key for a pair of images\"\"\"\n",
    "        hash1 = self.get_file_hash(img1_path)\n",
    "        hash2 = self.get_file_hash(img2_path)\n",
    "        return f\"{hash1}_{hash2}\"\n",
    "    \n",
    "    def get_cached_features(self, img1_path, img2_path):\n",
    "        \"\"\"Get cached features if available\"\"\"\n",
    "        cache_key = self.get_cache_key(img1_path, img2_path)\n",
    "        \n",
    "        if cache_key in self.cache_index:\n",
    "            cache_file = self.cache_dir / f\"{cache_key}.pkl\"\n",
    "            if cache_file.exists():\n",
    "                try:\n",
    "                    with open(cache_file, 'rb') as f:\n",
    "                        return pickle.load(f)\n",
    "                except:\n",
    "                    # Remove corrupted cache entry\n",
    "                    del self.cache_index[cache_key]\n",
    "                    self.save_cache_index()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def cache_features(self, img1_path, img2_path, features):\n",
    "        \"\"\"Cache extracted features\"\"\"\n",
    "        cache_key = self.get_cache_key(img1_path, img2_path)\n",
    "        cache_file = self.cache_dir / f\"{cache_key}.pkl\"\n",
    "        \n",
    "        try:\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(features, f)\n",
    "            \n",
    "            self.cache_index[cache_key] = {\n",
    "                'img1': img1_path,\n",
    "                'img2': img2_path,\n",
    "                'cache_file': str(cache_file)\n",
    "            }\n",
    "            self.save_cache_index()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error caching features: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a06e53-e525-4560-8494-ee66cf95ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_features(file_path=\"features_dataset.npz\"):\n",
    "    \"\"\"\n",
    "    Load pre-extracted features from disk\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Features file not found at {file_path}\")\n",
    "            return None, None, None\n",
    "            \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        # Check if required keys exist\n",
    "        required_keys = ['features', 'labels']\n",
    "        for key in required_keys:\n",
    "            if key not in data:\n",
    "                print(f\"Required key '{key}' not found in {file_path}\")\n",
    "                return None, None, None\n",
    "        \n",
    "        X = data['features']\n",
    "        y = data['labels']\n",
    "        \n",
    "        # Handle image_pairs safely (it might not exist)\n",
    "        image_pairs = data.get('image_pairs', None)\n",
    "        \n",
    "        print(f\"Loaded {len(X)} feature vectors from {file_path}\")\n",
    "        print(f\"Feature vector size: {X.shape[1]}\")\n",
    "        print(f\"Genuine signatures: {sum(y)} ({sum(y)/len(y)*100:.1f}%)\")\n",
    "        print(f\"Forged signatures: {len(y)-sum(y)} ({(len(y)-sum(y))/len(y)*100:.1f}%)\")\n",
    "        \n",
    "        return X, y, image_pairs\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading features: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e207c-7485-4dd6-aa54-b2985bc86d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check what we have\n",
    "print(\"Current state:\")\n",
    "print(f\"X is None: {X is None}\")\n",
    "print(f\"y is None: {y is None}\")\n",
    "\n",
    "if X is not None and y is not None:\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"X type: {type(X)}\")\n",
    "    print(f\"y type: {type(y)}\")\n",
    "\n",
    "# Check if file exists\n",
    "print(f\"features_dataset.npz exists: {os.path.exists('features_dataset.npz')}\")\n",
    "\n",
    "# If file exists, try to manually inspect it\n",
    "if os.path.exists('features_dataset.npz'):\n",
    "    try:\n",
    "        data = np.load('features_dataset.npz')\n",
    "        print(f\"Keys in file: {list(data.keys())}\")\n",
    "        for key in data.keys():\n",
    "            print(f\"{key} shape: {data[key].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2426cf-ee1f-44c6-a91a-17a1d4ce400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "# First check if features_dataset.npz exists\n",
    "if os.path.exists(\"features_dataset.npz\"):\n",
    "    print(\"Found existing features file, loading...\")\n",
    "    X, y, _ = load_saved_features(\"features_dataset.npz\")\n",
    "    \n",
    "if X is None or y is None:\n",
    "    print(\"No valid features loaded. You need to extract features first.\")\n",
    "    print(\"This may take a while...\")\n",
    "    \n",
    "    # Check if the required input files exist\n",
    "    if not os.path.exists(csv_file):\n",
    "        print(f\"ERROR: CSV file not found at {csv_file}\")\n",
    "        raise FileNotFoundError(f\"CSV file not found at {csv_file}\")\n",
    "    \n",
    "    if not os.path.exists(img_dir):\n",
    "        print(f\"ERROR: Image directory not found at {img_dir}\")\n",
    "        raise FileNotFoundError(f\"Image directory not found at {img_dir}\")\n",
    "    \n",
    "    # Extract features\n",
    "    X, y, _ = extract_and_save_all_features(csv_file, img_dir, \"features_dataset.npz\", subset_size)\n",
    "    \n",
    "    if X is None or y is None:\n",
    "        print(\"ERROR: Feature extraction failed.\")\n",
    "        raise ValueError(\"Feature extraction failed\")\n",
    "else:\n",
    "    print(\"Successfully loaded features from file!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002cb18-7539-4a69-8bc1-4988488a2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the working feature extraction function\n",
    "def extract_hybrid_signature_features(img1_path, img2_path, size=(128, 64)):\n",
    "    \"\"\"\n",
    "    Extract a hybrid set of features - proven features + selected advanced ones\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess images\n",
    "        img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img1 is None or img2 is None:\n",
    "            return None\n",
    "        \n",
    "        # Enhanced preprocessing\n",
    "        img1 = cv2.bilateralFilter(img1, 9, 75, 75)  # Noise reduction\n",
    "        img2 = cv2.bilateralFilter(img2, 9, 75, 75)\n",
    "        \n",
    "        # Multiple scale analysis\n",
    "        scales = [(128, 64), (256, 128), (64, 32)]\n",
    "        features = []\n",
    "        \n",
    "        for scale in scales:\n",
    "            img1_scaled = cv2.resize(img1, scale)\n",
    "            img2_scaled = cv2.resize(img2, scale)\n",
    "            \n",
    "            # SSIM at different scales\n",
    "            ssim_val = ssim(img1_scaled, img2_scaled)\n",
    "            features.append(ssim_val)\n",
    "            \n",
    "            # Histogram comparison at multiple scales\n",
    "            for bins in [32, 64]:\n",
    "                hist1 = cv2.calcHist([img1_scaled], [0], None, [bins], [0, 256])\n",
    "                hist2 = cv2.calcHist([img2_scaled], [0], None, [bins], [0, 256])\n",
    "                cv2.normalize(hist1, hist1, 0, 1, cv2.NORM_MINMAX)\n",
    "                cv2.normalize(hist2, hist2, 0, 1, cv2.NORM_MINMAX)\n",
    "                \n",
    "                features.append(cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL))\n",
    "                features.append(cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA))\n",
    "        \n",
    "        # Writer-specific features\n",
    "        # 1. Slant analysis\n",
    "        def calculate_slant(img):\n",
    "            edges = cv2.Canny(img, 50, 150)\n",
    "            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=50)\n",
    "            angles = []\n",
    "            if lines is not None:\n",
    "                for line in lines[:10]:  # Top 10 lines\n",
    "                    angle = line[0][1]\n",
    "                    angles.append(angle)\n",
    "            return np.mean(angles) if angles else 0\n",
    "        \n",
    "        slant1 = calculate_slant(img1)\n",
    "        slant2 = calculate_slant(img2)\n",
    "        features.extend([slant1, slant2, abs(slant1 - slant2)])\n",
    "        \n",
    "        # 2. Aspect ratio analysis\n",
    "        def get_bounding_box_features(img):\n",
    "            contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if contours:\n",
    "                x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "                return w/h, w, h\n",
    "            return 1.0, 0, 0\n",
    "        \n",
    "        aspect1, w1, h1 = get_bounding_box_features(img1)\n",
    "        aspect2, w2, h2 = get_bounding_box_features(img2)\n",
    "        features.extend([aspect1, aspect2, abs(aspect1 - aspect2), abs(w1-w2), abs(h1-h2)])\n",
    "        \n",
    "        # 3. Pressure variation (simulated from thickness)\n",
    "        def estimate_pressure_variation(img):\n",
    "            # Simulate pressure from line thickness\n",
    "            _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "            if not binary.any():\n",
    "                return 0.0\n",
    "            distances = cv2.distanceTransform(binary, cv2.DIST_L2, 5)\n",
    "            valid_distances = distances[distances > 0]\n",
    "            return np.std(valid_distances) if len(valid_distances) > 1 else 0.0\n",
    "        \n",
    "        pressure_var1 = estimate_pressure_variation(img1)\n",
    "        pressure_var2 = estimate_pressure_variation(img2)\n",
    "        features.extend([pressure_var1, pressure_var2, abs(pressure_var1 - pressure_var2)])\n",
    "        \n",
    "        # Original proven features\n",
    "        orb = cv2.ORB_create()\n",
    "        kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "        kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "        \n",
    "        if des1 is not None and des2 is not None and len(kp1) > 0 and len(kp2) > 0:\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            matches = bf.match(des1, des2)\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "            \n",
    "            num_matches = len(matches)\n",
    "            avg_distance = sum(m.distance for m in matches) / num_matches if num_matches > 0 else 100\n",
    "            match_ratio = num_matches / min(len(kp1), len(kp2)) if min(len(kp1), len(kp2)) > 0 else 0\n",
    "            \n",
    "            features.extend([num_matches, avg_distance, len(kp1), len(kp2), match_ratio])\n",
    "        else:\n",
    "            features.extend([0, 100, 0, 0, 0])\n",
    "        \n",
    "        features = np.array(features, dtype=np.float64)\n",
    "        features = np.nan_to_num(features, nan=0.0, posinf=100.0, neginf=-100.0)\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {e}\")\n",
    "        return None\n",
    "\n",
    "# Now run the data processing with this definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f2465-ef96-4200-9286-1780f13b1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hybrid_signature_features_cached(img1_path, img2_path, cache_manager=None, size=(128, 64)):\n",
    "    \"\"\"\n",
    "    Extract features with caching support\n",
    "    \"\"\"\n",
    "    # Try to get from cache first\n",
    "    if cache_manager:\n",
    "        cached_features = cache_manager.get_cached_features(img1_path, img2_path)\n",
    "        if cached_features is not None:\n",
    "            print(f\"Using cached features for {os.path.basename(img1_path)} and {os.path.basename(img2_path)}\")\n",
    "            return cached_features\n",
    "    \n",
    "    # Extract features if not in cache\n",
    "    features = extract_hybrid_signature_features(img1_path, img2_path, size)\n",
    "    \n",
    "    # Cache the features\n",
    "    if cache_manager and features is not None:\n",
    "        cache_manager.cache_features(img1_path, img2_path, features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a144b-20b4-4b58-a12f-fe9d83da8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_all_features(csv_file, img_dir, output_file=\"features_dataset.npz\", subset_size=None):\n",
    "    \"\"\"\n",
    "    Extract all features once and save them to disk\n",
    "    \"\"\"\n",
    "    print(f\"Extracting features for entire dataset from {csv_file}...\")\n",
    "    \n",
    "    # Load CSV file\n",
    "    data = pd.read_csv(csv_file, header=0)\n",
    "    \n",
    "    if subset_size and subset_size < len(data):\n",
    "        data = data.sample(subset_size, random_state=42)\n",
    "        print(f\"Using subset of {len(data)} rows\")\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    image_pairs = []\n",
    "    processed = 0\n",
    "    \n",
    "    # Initialize cache manager\n",
    "    cache_manager = FeatureCache()\n",
    "    \n",
    "    for idx, row in data.iterrows():\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Processing pair {idx}/{len(data)}...\")\n",
    "        \n",
    "        img1_path = os.path.join(img_dir, row[0])\n",
    "        img2_path = os.path.join(img_dir, row[1])\n",
    "        label = int(row[2])\n",
    "        \n",
    "        # Extract features with caching\n",
    "        features = extract_hybrid_signature_features_cached(img1_path, img2_path, cache_manager)\n",
    "        \n",
    "        if features is not None:\n",
    "            all_features.append(features)\n",
    "            all_labels.append(label)\n",
    "            image_pairs.append((row[0], row[1]))\n",
    "            processed += 1\n",
    "        \n",
    "        if processed % 100 == 0:\n",
    "            print(f\"Processed {processed} valid pairs\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(all_features)\n",
    "    y = np.array(all_labels)\n",
    "    \n",
    "    # Clean data\n",
    "    if np.isnan(X).any() or np.isinf(X).any():\n",
    "        print(\"WARNING: Dataset contains NaN or infinite values. Cleaning...\")\n",
    "        X = np.nan_to_num(X, nan=0.0, posinf=100.0, neginf=-100.0)\n",
    "    \n",
    "    # Save everything\n",
    "    np.savez_compressed(output_file, \n",
    "                       features=X, \n",
    "                       labels=y, \n",
    "                       image_pairs=image_pairs)\n",
    "    \n",
    "    print(f\"Saved {len(X)} feature vectors to {output_file}\")\n",
    "    return X, y, image_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5dd07-a1ab-4948-9054-1759f8aabdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_pair_features(img1_path, img2_path):\n",
    "    \"\"\"Extract features for a single image pair\"\"\"\n",
    "    try:\n",
    "        # Initialize cache manager if not exists\n",
    "        if not hasattr(extract_single_pair_features, 'cache_manager'):\n",
    "            extract_single_pair_features.cache_manager = FeatureCache()\n",
    "        \n",
    "        # Extract features with caching\n",
    "        features = extract_hybrid_signature_features_cached(\n",
    "            img1_path, img2_path, \n",
    "            extract_single_pair_features.cache_manager\n",
    "        )\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing pair {img1_path}, {img2_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de620f4-dbf5-4a05-905e-3b3459d22aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "try:\n",
    "    data = pd.read_csv(csv_file, header=0)\n",
    "    print(f\"Loaded CSV with {len(data)} rows\")\n",
    "    print(f\"First few rows of CSV:\\n{data.head()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    \n",
    "pairs = []\n",
    "labels = []\n",
    "processed = 0\n",
    "errors = 0\n",
    "\n",
    "# If subset size is specified, take a random subset\n",
    "if subset_size and subset_size < len(data):\n",
    "    data = data.sample(subset_size, random_state=42)\n",
    "    print(f\"Using subset of {len(data)} rows\")\n",
    "\n",
    "print(f\"Starting to process {len(data)} pairs...\")\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    if idx % 50 == 0:\n",
    "        print(f\"Processing pair {idx}/{len(data)}...\")\n",
    "    \n",
    "    try:\n",
    "        # Get image paths and label - using integer indexing to be safe\n",
    "        img1_path = os.path.join(img_dir, str(row.iloc[0]).strip())\n",
    "        img2_path = os.path.join(img_dir, str(row.iloc[1]).strip())\n",
    "        label = int(row.iloc[2])\n",
    "        \n",
    "        # Check if files exist\n",
    "        if not os.path.exists(img1_path):\n",
    "            if errors < 5:\n",
    "                print(f\"Warning: Image not found at {img1_path}\")\n",
    "            errors += 1\n",
    "            continue\n",
    "            \n",
    "        if not os.path.exists(img2_path):\n",
    "            if errors < 5:\n",
    "                print(f\"Warning: Image not found at {img2_path}\")\n",
    "            errors += 1\n",
    "            continue\n",
    "           \n",
    "        # Extract features for this pair\n",
    "        pair_features = extract_single_pair_features(img1_path, img2_path)\n",
    "        if pair_features is not None:\n",
    "            pairs.append(pair_features)\n",
    "            labels.append(label)\n",
    "            processed += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        if errors < 5:\n",
    "            print(f\"Error processing pair {idx}: {e}\")\n",
    "        errors += 1\n",
    "\n",
    "# Process results after the loop completes\n",
    "if processed == 0:\n",
    "    print(\"No valid pairs were processed!\")\n",
    "    X, y = None, None\n",
    "else:\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(pairs)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    # Clean data\n",
    "    if np.isnan(X).any() or np.isinf(X).any():\n",
    "        print(\"WARNING: Dataset contains NaN or infinite values. Cleaning...\")\n",
    "        X = np.nan_to_num(X, nan=0.0, posinf=100.0, neginf=-100.0)\n",
    "    \n",
    "    print(f\"Successfully processed {processed} pairs out of {len(data)} total\")\n",
    "    print(f\"Feature shape: {X.shape}\")\n",
    "    print(f\"Errors encountered: {errors}\")\n",
    "    \n",
    "    # Save features\n",
    "    np.savez_compressed(\"features_dataset.npz\", \n",
    "                       features=X, \n",
    "                       labels=y)\n",
    "    \n",
    "    print(f\"Saved {len(X)} feature vectors to features_dataset.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c7850-caca-4e69-bf8a-1028bdc36c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "test_size = 0.25\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "test_size_count = int(len(X) * test_size)\n",
    "test_indices = indices[:test_size_count]\n",
    "train_indices = indices[test_size_count:]\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "print(f\"Training set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")\n",
    "print(f\"Genuine signatures: {sum(y_train)} / {len(y_train)} in training, {sum(y_test)} / {len(y_test)} in test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f71add3-28f9-4136-9234-764af21eaf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8\n",
    "def test(network, X_test, y_test):\n",
    "    \"\"\"Tests the model using signature verification features.\"\"\"\n",
    "    network.eval()\n",
    "    \n",
    "    # Convert to PyTorch tensors if they aren't already\n",
    "    if not isinstance(X_test, torch.Tensor):\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    if not isinstance(y_test, torch.Tensor):\n",
    "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Move to device\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_X = X_test[i:i+batch_size]\n",
    "            batch_y = y_test[i:i+batch_size]\n",
    "            \n",
    "            output = network(batch_X)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b549b-8fb1-4b38-bb52-19288f06b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignatureDataAugmentor:\n",
    "    def __init__(self, noise_factor=0.01, flip_prob=0.1):\n",
    "        self.noise_factor = noise_factor\n",
    "        self.flip_prob = flip_prob\n",
    "    \n",
    "    def add_noise(self, X):\n",
    "        \"\"\"Add Gaussian noise to features\"\"\"\n",
    "        noise = np.random.normal(0, self.noise_factor, X.shape)\n",
    "        return X + noise\n",
    "    \n",
    "    def feature_dropout(self, X, dropout_rate=0.1):\n",
    "        \"\"\"Randomly set some features to zero\"\"\"\n",
    "        mask = np.random.binomial(1, 1-dropout_rate, X.shape)\n",
    "        return X * mask\n",
    "    \n",
    "    def augment_batch(self, X, y, augment_ratio=2):\n",
    "        \"\"\"Augment a batch of data\"\"\"\n",
    "        augmented_X = [X]\n",
    "        augmented_y = [y]\n",
    "        \n",
    "        for _ in range(augment_ratio):\n",
    "            # Add noise\n",
    "            X_noise = self.add_noise(X)\n",
    "            augmented_X.append(X_noise)\n",
    "            augmented_y.append(y)\n",
    "            \n",
    "            # Feature dropout\n",
    "            X_dropout = self.feature_dropout(X)\n",
    "            augmented_X.append(X_dropout)\n",
    "            augmented_y.append(y)\n",
    "        \n",
    "        return np.vstack(augmented_X), np.hstack(augmented_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b594948-6763-4d6c-9cf7-a41e12b9dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, optimizer, X_train, y_train, augmentor=None, epochs=20):\n",
    "    \"\"\"Trains the model using signature verification features.\n",
    "\n",
    "    Parameters:\n",
    "        - network (torch.nn.Module): The neural network\n",
    "        - optimizer (torch.optim): The optimizer for the network  \n",
    "        - X_train (torch.Tensor): Training features\n",
    "        - y_train (torch.Tensor): Training labels\n",
    "    \"\"\"\n",
    "    network.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Augment data each epoch\n",
    "        if augmentor:\n",
    "            X_aug, y_aug = augmentor.augment_batch(X_train, y_train, augment_ratio=1)\n",
    "        else:\n",
    "            X_aug, y_aug = X_train, y_train\n",
    "        \n",
    "        # Train on augmented data\n",
    "        batch_size = 64\n",
    "        for i in range(0, len(X_aug), batch_size):\n",
    "            batch_X = torch.tensor(X_aug[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(y_aug[i:i+batch_size], dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = network(batch_X)\n",
    "            loss = F.nll_loss(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99310aba-685f-42b0-bb3a-2791bbb32be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Enhanced objective function with class weighting and MLflow logging.\"\"\"\n",
    "    \n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log trial parameters\n",
    "        mlflow.log_params(trial.params)\n",
    "        \n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "        \n",
    "        input_size = X_train.shape[1]\n",
    "        model = OptimizedSignatureNet(trial, input_size).to(device)\n",
    "        \n",
    "        # RMSprop works best based on results\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(),\n",
    "            lr=trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
    "            weight_decay=trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "        )\n",
    "        \n",
    "        # Training loop with early stopping\n",
    "        best_accuracy = 0\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(20):  # Increase epochs slightly\n",
    "            model.train()\n",
    "            for i in range(0, len(X_train), 64):\n",
    "                batch_X = torch.tensor(X_train[i:i+64], dtype=torch.float32).to(device)\n",
    "                batch_y = torch.tensor(y_train[i:i+64], dtype=torch.long).to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(batch_X)\n",
    "                loss = F.nll_loss(output, batch_y, weight=class_weights)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            accuracy = test(model, X_test, y_test)\n",
    "            \n",
    "            # Log epoch metrics\n",
    "            mlflow.log_metric(\"accuracy\", accuracy, step=epoch)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "            trial.report(accuracy, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Log final metrics\n",
    "        mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
    "        \n",
    "        return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589dd28-cc5a-4a19-8bc0-474d670e3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=f\"signature_verification_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "    # Log dataset information\n",
    "    mlflow.log_params({\n",
    "        \"dataset_size\": len(X),\n",
    "        \"train_size\": len(X_train),\n",
    "        \"test_size\": len(X_test),\n",
    "        \"feature_size\": X.shape[1],\n",
    "        \"genuine_train\": sum(y_train),\n",
    "        \"forgery_train\": len(y_train) - sum(y_train),\n",
    "        \"genuine_test\": sum(y_test),\n",
    "        \"forgery_test\": len(y_test) - sum(y_test)\n",
    "    })\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, X_train_scaled, y_train, X_test_scaled, y_test),\n",
    "        n_trials=150  # Increase for better results\n",
    "    )\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best single model accuracy: {best_trial.value}\")\n",
    "    \n",
    "    # Log best parameters\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in best_trial.params.items()})\n",
    "    mlflow.log_metric(\"best_single_model_accuracy\", best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dda68e-1c52-4689-ae54-775dc0a9a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best single model accuracy: {study.best_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a57583-906f-4523-be67-65ff38ecabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleSignatureVerifier:\n",
    "    def __init__(self, models, weights=None):\n",
    "        \"\"\"\n",
    "        Initialize ensemble with multiple trained models\n",
    "        \n",
    "        Args:\n",
    "            models: List of trained models\n",
    "            weights: Optional weights for each model (defaults to equal weights)\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Fixed: uncommented this line\n",
    "        \n",
    "        # Move all models to device and set to eval mode\n",
    "        for model in self.models:\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "        \n",
    "        # Set weights for each model\n",
    "        if weights is None:\n",
    "            self.weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            assert len(weights) == len(models), \"Number of weights must match number of models\"\n",
    "            self.weights = weights\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Get weighted average probabilities from all models\"\"\"\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.tensor(X, dtype=torch.float32)\n",
    "        X = X.to(self.device)\n",
    "        \n",
    "        all_probas = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model, weight in zip(self.models, self.weights):\n",
    "                output = model(X)\n",
    "                probas = torch.softmax(output, dim=1)\n",
    "                all_probas.append(probas.cpu().numpy() * weight)\n",
    "        \n",
    "        return np.sum(all_probas, axis=0)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using ensemble\"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        return np.argmax(probas, axis=1)\n",
    "    \n",
    "    def predict_with_confidence(self, X, threshold=0.85):\n",
    "        \"\"\"Make predictions only for high-confidence cases\"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        confidence = np.max(probas, axis=1)\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        \n",
    "        # Mark low-confidence predictions as uncertain\n",
    "        uncertain_mask = confidence < threshold\n",
    "        predictions[uncertain_mask] = -1  # -1 indicates uncertain\n",
    "        \n",
    "        return predictions, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c089fe-6e80-4f00-aa6e-bb8043908c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, optimizer, X_train, y_train, epochs=10):\n",
    "    \"\"\"Simple training function that ensures device consistency\"\"\"\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Convert to tensors and move to device\n",
    "    if not isinstance(X_train, torch.Tensor):\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    if not isinstance(y_train, torch.Tensor):\n",
    "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    \n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    \n",
    "    batch_size = 64\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            batch_X = X_train[i:i+batch_size]\n",
    "            batch_y = y_train[i:i+batch_size]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = torch.nn.functional.nll_loss(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9bdd9-93ea-42dd-918e-12d307baca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_from_study(study, X_train, y_train, top_n=5):\n",
    "    \"\"\"Create ensemble from top N trials\"\"\"\n",
    "    best_trials = sorted(study.trials, key=lambda t: t.value if hasattr(t, 'value') and t.value is not None else 0, reverse=True)[:top_n]\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    # Import the model class\n",
    "   \n",
    "    for trial in best_trials:\n",
    "        # Create a new trial-like object for initialization\n",
    "        class TrialMock:\n",
    "            def __init__(self, params):\n",
    "                self.params = params\n",
    "            \n",
    "            def suggest_int(self, name, *args, **kwargs):\n",
    "                return self.params[name]\n",
    "            \n",
    "            def suggest_float(self, name, *args, **kwargs):\n",
    "                return self.params[name]\n",
    "        \n",
    "        # Create model with trial parameters\n",
    "        mock_trial = TrialMock(trial.params)\n",
    "        model = OptimizedSignatureNet(mock_trial, X_train.shape[1])\n",
    "        model.to(device)\n",
    "        \n",
    "        # Create optimizer with trial parameters\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(),\n",
    "            lr=trial.params['lr'],\n",
    "            weight_decay=trial.params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        train_model_simple(model, optimizer, X_train, y_train, epochs=10)\n",
    "        models.append(model)\n",
    "    \n",
    "    return EnsembleSignatureVerifier(models)\n",
    "\n",
    "ensemble_model = create_ensemble_from_study(study, X_train_scaled, y_train, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d29ab5-5f18-421a-bbed-01ab10c2a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions = ensemble_model.predict(X_test_scaled)\n",
    "ensemble_acc = np.mean(ensemble_predictions == y_test)\n",
    "print(f\"Ensemble accuracy: {ensemble_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d42457-3634-416c-82bc-37c946501156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfidenceEvaluator:\n",
    "    def __init__(self, model, threshold=0.85):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def evaluate_with_confidence(self, X_test, y_test):\n",
    "        \"\"\"Evaluate model with confidence thresholding\"\"\"\n",
    "        if hasattr(self.model, 'predict_with_confidence'):\n",
    "            predictions, confidence = self.model.predict_with_confidence(X_test, self.threshold)\n",
    "        else:\n",
    "            probas = self.model.predict_proba(X_test) if hasattr(self.model, 'predict_proba') else torch.softmax(self.model(torch.tensor(X_test, dtype=torch.float32).to(device)), dim=1).cpu().numpy()\n",
    "            confidence = np.max(probas, axis=1)\n",
    "            predictions = np.argmax(probas, axis=1)\n",
    "            predictions[confidence < self.threshold] = -1\n",
    "        \n",
    "        # Calculate metrics for different confidence levels\n",
    "        results = {}\n",
    "        for conf_thresh in [0.5, 0.7, 0.85, 0.9, 0.95]:\n",
    "            high_conf_mask = confidence >= conf_thresh\n",
    "            if np.sum(high_conf_mask) > 0:\n",
    "                accurate_predictions = predictions[high_conf_mask]\n",
    "                accurate_true = y_test[high_conf_mask]\n",
    "                \n",
    "                # Only count non-uncertain predictions\n",
    "                certain_mask = accurate_predictions != -1\n",
    "                if np.sum(certain_mask) > 0:\n",
    "                    accuracy = np.mean(accurate_predictions[certain_mask] == accurate_true[certain_mask])\n",
    "                    coverage = np.sum(high_conf_mask) / len(y_test)\n",
    "                    results[conf_thresh] = {'accuracy': accuracy, 'coverage': coverage}\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb14b9-297a-4db7-a4fa-327dd0587a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this cell before the torch.save\n",
    "def analyze_errors(model, X_test, y_test):\n",
    "    \"\"\"Analyze prediction errors in detail\"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    probas = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Find misclassified examples\n",
    "    errors = predictions != y_test\n",
    "    error_indices = np.where(errors)[0]\n",
    "    \n",
    "    error_analysis = {\n",
    "        'total_errors': len(error_indices),\n",
    "        'error_rate': len(error_indices) / len(y_test),\n",
    "        'false_positives': np.sum((predictions == 1) & (y_test == 0)),\n",
    "        'false_negatives': np.sum((predictions == 0) & (y_test == 1))\n",
    "    }\n",
    "    \n",
    "    if probas is not None:\n",
    "        # Analyze confidence of errors\n",
    "        error_probas = probas[error_indices]\n",
    "        error_confidence = np.max(error_probas, axis=1)\n",
    "        error_analysis['avg_error_confidence'] = np.mean(error_confidence)\n",
    "        error_analysis['high_conf_errors'] = np.sum(error_confidence > 0.9)\n",
    "    \n",
    "    return error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87dc1b5-95aa-4b86-91dc-7f1cc8430a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ConfidenceEvaluator(ensemble_model)\n",
    "confidence_results = evaluator.evaluate_with_confidence(X_test_scaled, y_test)\n",
    "\n",
    "print(\"\\nConfidence-based results:\")\n",
    "for threshold, metrics in confidence_results.items():\n",
    "    print(f\"Threshold {threshold}: Accuracy={metrics['accuracy']:.3f}, Coverage={metrics['coverage']:.3f}\")\n",
    "\n",
    "# Error analysis\n",
    "errors = analyze_errors(ensemble_model, X_test_scaled, y_test)\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"Total errors: {errors['total_errors']}\")\n",
    "print(f\"Error rate: {errors['error_rate']:.3f}\")\n",
    "print(f\"False positives: {errors['false_positives']}\")\n",
    "print(f\"False negatives: {errors['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517a92e-588e-4133-9d33-14589f3442c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When saving the ensemble (modify your training code)\n",
    "def save_complete_ensemble(study, ensemble_model, scaler, imputer, filename='best_signature_ensemble.pth'):\n",
    "    \"\"\"Save ensemble with model architectures\"\"\"\n",
    "    # Get the best trial parameters\n",
    "    best_trial = study.best_trial\n",
    "    best_params = best_trial.params\n",
    "    \n",
    "    # Save everything needed for reconstruction\n",
    "    checkpoint = {\n",
    "        'models': [model.state_dict() for model in ensemble_model.models],\n",
    "        'weights': ensemble_model.weights,\n",
    "        'scaler': scaler,\n",
    "        'imputer': imputer,\n",
    "        'model_params': best_params,  # Save the architecture parameters\n",
    "        'input_size': ensemble_model.models[0].layers[0].in_features  # Save input size\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Complete ensemble saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e4a37-5c0b-4845-a30c-e68c37b671fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "with mlflow.start_run(run_name=f\"ensemble_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\", nested=True):\n",
    "    try:\n",
    "        # Log ensemble performance\n",
    "        mlflow.log_metric(\"ensemble_accuracy\", ensemble_acc)\n",
    "        \n",
    "        # Log confidence-based results\n",
    "        for threshold, metrics in confidence_results.items():\n",
    "            mlflow.log_metric(f\"accuracy_at_{threshold}_confidence\", metrics['accuracy'])\n",
    "            mlflow.log_metric(f\"coverage_at_{threshold}_confidence\", metrics['coverage'])\n",
    "        \n",
    "        # Log error analysis\n",
    "        mlflow.log_metrics({\n",
    "            \"total_errors\": errors['total_errors'],\n",
    "            \"error_rate\": errors['error_rate'],\n",
    "            \"false_positives\": errors['false_positives'],\n",
    "            \"false_negatives\": errors['false_negatives']\n",
    "        })\n",
    "        \n",
    "        # Create signature BEFORE moving models to CPU\n",
    "        signature = infer_signature(X_test_scaled, ensemble_model.predict_proba(X_test_scaled))\n",
    "        \n",
    "        # Save model ensemble with MLflow - using a simpler approach\n",
    "        class EnsembleModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "            def __init__(self, models_state_dicts, layer_sizes_list, dropout_rates, weights, scaler, imputer):\n",
    "                self.models_state_dicts = models_state_dicts\n",
    "                self.layer_sizes_list = layer_sizes_list\n",
    "                self.dropout_rates = dropout_rates\n",
    "                self.weights = weights\n",
    "                self.scaler = scaler\n",
    "                self.imputer = imputer\n",
    "                self.models = None\n",
    "                \n",
    "            def load_context(self, context):\n",
    "                \"\"\"Load models when needed\"\"\"\n",
    "                if self.models is None:\n",
    "                    self.models = []\n",
    "                    for state_dict, layer_sizes, dropout_rate in zip(self.models_state_dicts, self.layer_sizes_list, self.dropout_rates):\n",
    "                        # Create model with exact layer sizes\n",
    "                        model = self.create_model_with_exact_sizes(layer_sizes, dropout_rate)\n",
    "                        model.load_state_dict(state_dict)\n",
    "                        model.eval()\n",
    "                        self.models.append(model)\n",
    "            \n",
    "            def create_model_with_exact_sizes(self, layer_sizes, dropout_rate):\n",
    "                \"\"\"Create model with exact layer sizes to match saved state dict\"\"\"\n",
    "                class ExactSizeModel(nn.Module):\n",
    "                    def __init__(self, layer_sizes, dropout_rate):\n",
    "                        super().__init__()\n",
    "                        self.layers = nn.ModuleList()\n",
    "                        self.batch_norms = nn.ModuleList()\n",
    "                        \n",
    "                        # Create layers with exact sizes\n",
    "                        for i in range(len(layer_sizes) - 1):\n",
    "                            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "                            self.batch_norms.append(nn.BatchNorm1d(layer_sizes[i + 1]))\n",
    "                        \n",
    "                        # Output layer\n",
    "                        self.output = nn.Linear(layer_sizes[-1], 2)\n",
    "                        self.dropout = nn.Dropout(dropout_rate)\n",
    "                    \n",
    "                    def forward(self, x):\n",
    "                        for layer, batch_norm in zip(self.layers, self.batch_norms):\n",
    "                            x = layer(x)\n",
    "                            x = batch_norm(x)\n",
    "                            x = F.relu(x)\n",
    "                            x = self.dropout(x)\n",
    "                        x = self.output(x)\n",
    "                        return F.log_softmax(x, dim=1)\n",
    "                \n",
    "                return ExactSizeModel(layer_sizes, dropout_rate)\n",
    "                        \n",
    "            def predict(self, context, model_input):\n",
    "                if self.models is None:\n",
    "                    self.load_context(context)\n",
    "                    \n",
    "                # Preprocess\n",
    "                X_imputed = self.imputer.transform(model_input)\n",
    "                X_scaled = self.scaler.transform(X_imputed)\n",
    "                \n",
    "                # Convert to tensor\n",
    "                X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "                \n",
    "                # Predict with ensemble\n",
    "                all_probas = []\n",
    "                for model, weight in zip(self.models, self.weights):\n",
    "                    with torch.no_grad():\n",
    "                        output = model(X_tensor)\n",
    "                        probas = torch.softmax(output, dim=1).numpy()\n",
    "                        all_probas.append(probas * weight)\n",
    "                \n",
    "                return np.sum(all_probas, axis=0)\n",
    "        \n",
    "        # Extract exact layer sizes and parameters from each model\n",
    "        models_state_dicts = []\n",
    "        layer_sizes_list = []\n",
    "        dropout_rates = []\n",
    "        \n",
    "        for model in ensemble_model.models:\n",
    "            # Get exact layer sizes\n",
    "            layer_sizes = [model.layers[0].in_features]  # Input size\n",
    "            for layer in model.layers:\n",
    "                layer_sizes.append(layer.out_features)\n",
    "            layer_sizes_list.append(layer_sizes)\n",
    "            \n",
    "            # Get dropout rate\n",
    "            dropout_rates.append(model.dropout_rate)\n",
    "            \n",
    "            # Move to CPU and get state dict\n",
    "            model.cpu()\n",
    "            models_state_dicts.append(model.state_dict())\n",
    "            # Move back to device\n",
    "            model.to(device)\n",
    "        \n",
    "        # Create wrapper with exact specifications\n",
    "        wrapped_model = EnsembleModelWrapper(\n",
    "            models_state_dicts,\n",
    "            layer_sizes_list,\n",
    "            dropout_rates,\n",
    "            ensemble_model.weights,\n",
    "            scaler,\n",
    "            imputer\n",
    "        )\n",
    "        \n",
    "        # Test that the wrapper can load properly\n",
    "        wrapped_model.load_context(None)\n",
    "        print(f\"Successfully loaded {len(wrapped_model.models)} models in wrapper\")\n",
    "        \n",
    "        # Log the model and get the model URI\n",
    "        run = mlflow.active_run()\n",
    "        model_uri = f\"runs:/{run.info.run_id}/ensemble_signature_verifier\"\n",
    "        \n",
    "        mlflow.pyfunc.log_model(\n",
    "            \"ensemble_signature_verifier\",\n",
    "            python_model=wrapped_model,\n",
    "            signature=signature\n",
    "        )\n",
    "        \n",
    "        save_complete_ensemble(study, ensemble_model, scaler, imputer, filename='best_signature_ensemble.pth')\n",
    "\n",
    "        # Register the model using the URI\n",
    "        registered_model = mlflow.register_model(\n",
    "            model_uri=model_uri,\n",
    "            name=\"ForgeryDetectionModel\"\n",
    "        )\n",
    "        \n",
    "        # Important: Explicitly set run to completed\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"ensemble_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "        mlflow.set_tag(\"status\", \"completed\")\n",
    "        \n",
    "        print(\"Model saved both locally and to MLflow!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Log the error and re-raise\n",
    "        mlflow.set_tag(\"status\", \"failed\")\n",
    "        mlflow.set_tag(\"error\", str(e))\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860029d-fa4f-493f-82f9-8c2da4f27e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ensemble_model_with_params(checkpoint_path, device):\n",
    "    \"\"\"Load ensemble model using saved parameters\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    scaler = checkpoint['scaler']\n",
    "    imputer = checkpoint['imputer']\n",
    "    model_weights = checkpoint['weights']\n",
    "    model_states = checkpoint['models']\n",
    "    model_params = checkpoint['model_params']\n",
    "    input_size = checkpoint['input_size']\n",
    "    \n",
    "    # Reconstruct models using saved parameters\n",
    "    models = []\n",
    "    for model_state in model_states:\n",
    "        # Create model with saved parameters\n",
    "        model = OptimizedSignatureNet(\n",
    "            input_size=input_size,\n",
    "            num_layers=model_params['num_layers'],\n",
    "            first_layer_size=model_params['first_layer_size'],\n",
    "            layer_reductions=[\n",
    "                model_params.get('layer_1_reduction', 0.8),\n",
    "                model_params.get('layer_2_reduction', 0.8),\n",
    "                model_params.get('layer_3_reduction', 0.8),\n",
    "                model_params.get('layer_4_reduction', 0.8)\n",
    "            ][:model_params['num_layers']-1],\n",
    "            dropout_rate=model_params['dropout_rate']\n",
    "        )\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    return models, scaler, imputer, model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617a1e6-a2e7-45d4-ae80-3a3e74a3b28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
